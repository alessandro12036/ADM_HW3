{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - What is the best anime in the world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1vpHmGKKVr3y"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import datetime as dt \n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "### 1.1. Get the list of animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "05q7ZZuI-GDE"
   },
   "outputs": [],
   "source": [
    "def take_n_urls(n):\n",
    "\n",
    "    main_url = \"https://myanimelist.net/topanime.php\"\n",
    "\n",
    "    # this list will contain all the urls we'll retrieve\n",
    "    urls = [] \n",
    "\n",
    "    # each page shows 50 elements and we can retrieve each page by manipulating the \"limit\" query\n",
    "    for limit in range(0, n, 50): \n",
    "        content = requests.get(main_url,\n",
    "                               params={\"limit\": limit})\n",
    "        if content.status_code == 404:\n",
    "            print(f\"Page with limit {limit} was not found. Interrumpting and returning pages found\")\n",
    "            break\n",
    "        soup = bs(content.content, \"html.parser\")\n",
    "\n",
    "        # from the content of each page we retrieve the portions that contain the urls\n",
    "        results = soup.find_all(\"a\", \n",
    "                                class_= \"hoverinfo_trigger fl-l ml12 mr8\")\n",
    "\n",
    "        # finally, we take the string containing each url by taking the attribute href,\n",
    "        # and we append them in the urls list\n",
    "        for result in results:\n",
    "            url = result[\"href\"]\n",
    "            if url not in urls:  # check for duplicates\n",
    "                urls.append(url)\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdJbPl0CWPPq",
    "outputId": "b98b3450-05af-4830-d7dc-e08e66c56092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading urls...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if \"urls.txt\" not in os.listdir():\n",
    "    urls = take_n_urls(20000)\n",
    "    # Since the output of this step has to be a txt file, here we write one with each\n",
    "    # url separated by a newline\n",
    "    with open(\"urls.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(urls_str))\n",
    "else:\n",
    "    with open(\"urls.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "        print(\"Loading urls...\")\n",
    "        urls = file.read().split(\"\\n\")\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIe7cbwc_zOt",
    "outputId": "268a24bd-5649-4cce-ff7d-5e9cdf87d09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19130\n",
      "https://myanimelist.net/anime/30839/Big_X_Episode_0\n"
     ]
    }
   ],
   "source": [
    "# we end up with 19131 urls. \n",
    "# I added a check that tells us when we have exceeded the length of the ranking list and returns what has been found\n",
    "# up until that moment (so to avoid losing any more time with get requests that point to nothing)\n",
    "# I know in the assignment they said 20000 but I'm fairly sure that's all the entries. \n",
    "# This is easy to see if we manually set the limit in the url and check the results. \n",
    "# For example: https://myanimelist.net/topanime.php?limit=15000 contains rankings 15001-15050. The first entry is\n",
    "# Big X Episode 0. If we check our list with urls[15000] (remember that our list is 0-indexed) we obtain the same result.\n",
    "# This to me seems to point to a correct behavior from the function, but let me know what you think.\n",
    "\n",
    "print(len(urls)) \n",
    "print(urls[15000])\n",
    "urls_str = list(map(str, urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl animes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: the index of article start with 0 and not 1 so all ranks are shifted by 1 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the directory where the html pages will be stored\n",
    "if \"html_pages\" not in os.listdir():\n",
    "    os.mkdir(\"html_pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "t-HVU_RiAfYf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_html_pages(urls):\n",
    "    if \"counter_pages\" not in os.listdir():\n",
    "        start = 0\n",
    "    else:\n",
    "        with open(\"counter_pages\", \"rb\") as counter_file:\n",
    "            start = pickle.load(counter_file) + 1\n",
    "\n",
    "    print(f\"Starting from anime #{start}\")\n",
    "    n = len(urls)\n",
    "    for i in range(start, n):\n",
    "        ranking_page = str(int(np.floor(i/50)))\n",
    "        if i % 50 == 0 or f\"ranking_page_{ranking_page}\" not in os.listdir(\"./html_pages\"):\n",
    "            os.mkdir(f\"html_pages/ranking_page_{ranking_page}\")\n",
    "        html_page = requests.get(urls[i])\n",
    "        sleep_modifier = 0\n",
    "        while html_page.status_code != 200: # if the status_code is not 200, we've exceeded the number of requests and have to wait\n",
    "            sleep_timer = 20+sleep_modifier\n",
    "            print(f\"Exceeded number of requests while retrieving page #{i}.\\nWaiting {sleep_timer} seconds\")\n",
    "            html_page.close()\n",
    "            time.sleep(sleep_timer)\n",
    "            html_page = requests.get(urls[i])\n",
    "            sleep_modifier += 1\n",
    "        with open (f\"html_pages/ranking_page_{ranking_page}/article_{i}.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(html_page.text)\n",
    "        with open (\"counter_pages\", \"wb\") as counter_file:\n",
    "            pickle.dump(i, counter_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from anime #175\n",
      "Exceeded number of requests while retrieving page #175.\n",
      "Waiting 5 seconds\n",
      "Exceeded number of requests while retrieving page #175.\n",
      "Waiting 6 seconds\n",
      "Exceeded number of requests while retrieving page #175.\n",
      "Waiting 7 seconds\n",
      "Exceeded number of requests while retrieving page #175.\n",
      "Waiting 8 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 5 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 6 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 7 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 8 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 9 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 10 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 11 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 12 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 13 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 14 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 15 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 16 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 17 seconds\n",
      "Exceeded number of requests while retrieving page #326.\n",
      "Waiting 18 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 5 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 6 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 7 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 8 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 9 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 10 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 11 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 12 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 13 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 14 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 15 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 16 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 17 seconds\n",
      "Exceeded number of requests while retrieving page #506.\n",
      "Waiting 18 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a25939384211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_html_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-023531323f58>\u001b[0m in \u001b[0;36msave_html_pages\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mf\"ranking_page_{ranking_page}\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./html_pages\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"html_pages/ranking_page_{ranking_page}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mhtml_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0msleep_modifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mhtml_page\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if the status_code is not 200, we've exceeded the number of requests and have to wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_html_pages(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages\n",
    "\n",
    "At this point, you should have all the html documents about the animes of interest and you can start to extract the animes informations. The list of information we desire for each anime and their format is the following:\n",
    "\n",
    "1. Anime Name (to save as `animeTitle`): String\n",
    "2. Anime Type (to save as `animeType`): String\n",
    "3. Number of episode (to save as `animeNumEpisode`): Integer\n",
    "4. Release and End Dates of anime (to save as `releaseDate` and `endDate`): Convert both release and end date into datetime format.\n",
    "5. Number of members (to save as `animeNumMembers`): Integer\n",
    "6. Score (to save as `animeScore`): Float\n",
    "7. Users (to save as `animeUsers`): Integer\n",
    "8. Rank (to save as `animeRank`): Integer\n",
    "9. Popularity (to save as `animePopularity`): Integer\n",
    "10. Synopsis (to save as `animeDescription`): String\n",
    "11. Related Anime (to save as `animeRelated`): Extract all the related animes, but only keep unique values and those that have a hyperlink associated to them. List of strings.\n",
    "12. Characters (to save as `animeCharacters`): List of strings.\n",
    "13. Voices (to save as `animeVoices`): List of strings\n",
    "14. Staff (to save as `animeStaff`): Include the staff name and their responsibility/task in a list of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the directory where the tsv files will be stored\n",
    "os.mkdir(\"tsv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_info(num_article, folder='tsv_files'):\n",
    "    ranking_page = str(int(np.floor(num_article/50)))\n",
    "    article=f'html_pages/ranking_page_{ranking_page}/article_{num_article}.html'\n",
    "    with open(article, \"r\", encoding=\"utf-8\") as file:\n",
    "        art= bs(file.read(), 'html.parser')\n",
    "    \n",
    "    #animeTitle\n",
    "    animeTitle = art.find('h1', {'class':\"title-name h1_bold_none\"}).string\n",
    "    #print('animeTitle :',animeTitle)\n",
    "    \n",
    "    \n",
    "    #animeType\n",
    "    animeType = art.find('span', {'class':\"information type\"}).string\n",
    "    #print('animeType :',animeType)\n",
    "    \n",
    "    \n",
    "    #animeNumEpisode and Dates (there is not specific name for those two info)\n",
    "    #list lines with tag <div class=\"spaceit_pad\">\n",
    "    lines = art.find_all('div', {'class':\"spaceit_pad\"})\n",
    "    for line in lines :\n",
    "        #for each div tag there is one span, so here we look for the span tag with 'Episodes:' and 'Aired'\n",
    "        sp= line.find('span', {'class':\"dark_text\"})\n",
    "        # to avoid error if there is no span\n",
    "        if sp is not None :\n",
    "            #for span 'Episodes' (and the div tag which corresponds)\n",
    "            if sp.string == 'Episodes:' :\n",
    "                #extract the content of the right div tag and take the third line which correspond to the number of episodes\n",
    "                animeNumEpisode = int(line.contents[2])\n",
    "                #animeNumEpisode = int(re.findall(r'-?\\d+\\.?\\d*', str(line))[0])           #if we want to use regex  \n",
    "            #for span 'Aired' (and the div tag which corresponds)\n",
    "            if sp.string == 'Aired:' :\n",
    "                str_dates = line.contents[2].split('\\n  ')[1]\n",
    "                #if \"Status: Finished Airing\" (there is a endDate)\n",
    "                if 'to' in str_dates :\n",
    "                    #extract the content of the right div tag and take the third line which correspond to the dates (fix the issue of '\\n')\n",
    "                    str_releaseDate, str_endDate = str_dates.split(' to ')\n",
    "                    #convert into a datetime\n",
    "                    date_format = \"%b %d, %Y\"\n",
    "                    releaseDate, endDate = dt.datetime.strptime(str_releaseDate, date_format), dt.datetime.strptime(str_endDate, date_format)\n",
    "                else :\n",
    "                    str_releaseDate = str_dates\n",
    "                    #convert into a datetime\n",
    "                    date_format = \"%b %d, %Y\"\n",
    "                    releaseDate = dt.datetime.strptime(str_releaseDate, date_format)\n",
    "                    endDate=''\n",
    "    #print('animeNumEpisode :',animeNumEpisode)\n",
    "    #print('releaseDate :',releaseDate)\n",
    "    #print('endDate :',endDate)\n",
    "    \n",
    "    \n",
    "    #animeNumMembers\n",
    "    animeNumMembers = int(art.find('span', {'class':\"numbers members\"}).contents[1].string.replace(',',''))\n",
    "    #print('animeNumMembers :',animeNumMembers)\n",
    "    \n",
    "    \n",
    "    #animeScore\n",
    "    animeScore = float(art.find('div', {'class':\"score-label\"}).string)\n",
    "    #print('animeScore :',animeScore)\n",
    "    \n",
    "    \n",
    "    #animeUsers\n",
    "    animeUsers = int(art.find('span', {'itemprop':\"ratingCount\"}).string)\n",
    "    #print('animeUsers :',animeUsers)\n",
    "    \n",
    "    \n",
    "    #animeRank\n",
    "    animeRank = int(art.find('span', {'class':\"numbers ranked\"}).contents[1].string.replace('#',''))\n",
    "    #print('animeRank :',animeRank)\n",
    "    \n",
    "    \n",
    "    #animePopularity\n",
    "    animePopularity = int(art.find('span', {'class':\"numbers popularity\"}).contents[1].string.replace('#',''))\n",
    "    #print('animePopularity :',animePopularity)\n",
    "    \n",
    "    \n",
    "    #animeDescription\n",
    "    desc = art.find('p', {'itemprop':\"description\"}).contents\n",
    "    animeDescription=''\n",
    "    #remove <br/> Tag and '\\n'\n",
    "    for ele in desc :\n",
    "        #delete tags with regex \n",
    "        ele = re.sub(re.compile('<.*?>'),'', str(ele))\n",
    "        animeDescription += ele\n",
    "    #print('animeDescription :',animeDescription.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    #animeRelated\n",
    "    animeRelated = []\n",
    "    #store the table which contain related animes\n",
    "    table = art.find('table', {'class':\"anime_detail_related_anime\"})\n",
    "    if table is not None :\n",
    "        #store all links/anime related with 'a' Tag\n",
    "        links = table.find_all('a')\n",
    "        for link in links :\n",
    "            # check if there is a hyperlink and add it in the list if yes \n",
    "            if (link.get('href') is not None) and (link.string is not None):\n",
    "                animeRelated += [link.string]\n",
    "        animeRelated=list(set(animeRelated))\n",
    "    else :\n",
    "        animeRelated=''\n",
    "    #print('animeRelated :',animeRelated)\n",
    "\n",
    "    \n",
    "    #animeCharacters\n",
    "    animeCharacters = art.find_all('h3', {'class':\"h3_characters_voice_actors\"})\n",
    "    animeCharacters = [char.string for char in animeCharacters]\n",
    "    #print('animeCharacters :',animeCharacters)\n",
    "    \n",
    "    \n",
    "    #animeVoices\n",
    "    td_Voices = art.find_all('td', {'class':\"va-t ar pl4 pr4\"})\n",
    "    animeVoices = [voice.find('a').string for voice in td_Voices]\n",
    "    #print('animeVoices :',animeVoices)\n",
    "    \n",
    "    \n",
    "    #animeStaff\n",
    "    #if there is a staff, the div which correspond to the table Staff is the second one (there are div with {'class':\"detail-characters-list clearfix\"})\n",
    "    if len(art.find_all('div', {'class':\"detail-characters-list clearfix\"}))>1 :\n",
    "        div_staff = art.find_all('div', {'class':\"detail-characters-list clearfix\"})[1] \n",
    "        td_staff = div_staff.find_all('td', {'class':\"borderClass\"})\n",
    "        animeStaff=[]\n",
    "        for td in td_staff :\n",
    "            if td.get('width') == None:\n",
    "                animeStaff.append([td.find('a').string,td.find('small').string])\n",
    "    #if there is not staff\n",
    "    else :\n",
    "        animeStaff = ''\n",
    "    #print('animeStaff :',animeStaff)\n",
    "    \n",
    "    #create a .tsv file with attributes\n",
    "    with open(f'{folder}/anime_{num_article}', 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        tsv_writer.writerow([animeTitle, animeType, animeNumEpisode, releaseDate, endDate, animeNumMembers, \\\n",
    "                            animeScore, animeUsers, animeRank, animePopularity, animeDescription, animeRelated, \\\n",
    "                            animeCharacters, animeVoices, animeStaff])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '?' does not match format '%b %d, %Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-388-4724ccb12d70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcollect_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-387-26c2cbf4f254>\u001b[0m in \u001b[0;36mcollect_info\u001b[1;34m(num_article, folder)\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[1;31m#convert into a datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0mdate_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%b %d, %Y\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                     \u001b[0mreleaseDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendDate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_releaseDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_endDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[0mstr_releaseDate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr_dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[0;32m    576\u001b[0m     format string.\"\"\"\n\u001b[1;32m--> 577\u001b[1;33m     \u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[1;32m--> 359\u001b[1;33m                          (data_string, format))\n\u001b[0m\u001b[0;32m    360\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
      "\u001b[1;31mValueError\u001b[0m: time data '?' does not match format '%b %d, %Y'"
     ]
    }
   ],
   "source": [
    "for i in range(len(urls)):\n",
    "    collect_info(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algorithmic question\n",
    "You consult for a personal trainer who has a *back-to-back sequence* of requests for appointments. A sequence of requests is of the form\n",
    "    > 30, 40, 25, 50, 30, 20\n",
    "where each number is the time that the person who makes the appointment wants to spend.\n",
    "You need to accept some requests, however you need a break between them, so you cannot accept two consecutive requests. For example, `[30, 50, 20]` is an acceptable solution (of duration *100*), but `[30, 40, 50, 20]` is not, because *30* and *40* are two consecutive appointments. Your goal is to provide to the personal trainer a schedule that maximizes the total length of the accepted appointments. For example, in the previous instance, the optimal solution is `[40, 50, 20]`, of total duration *110*.\n",
    "1. Write an algorithm that computes the acceptable solution with the longest possible duration.\n",
    "2. Implement a program that given in input an instance in the form given above, gives the optimal solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write an algorithm that computes the acceptable solution with the longest possible duration.\n",
    "\n",
    "##### Here we consider that all values in the instance are unique and len(instance) = n\n",
    "\n",
    "To compute the acceptable solution with the longest possible duration, we have to follow several steps :\n",
    "1. Compute every possible solution : So for that, list all sublists which represent each possible list of appointments.\n",
    "2. For each sublist, tell if it is acceptable or not, so if there are two consecutive appointments or not.\n",
    "3. Compute the total duration of each acceptable solution.\n",
    "4. Finally, return the solution which correspond to the maximum duration.\n",
    "\n",
    "```\n",
    "Input: \n",
    "    instance: list of length n\n",
    "\n",
    "function optimal_solution(instance):\n",
    "    n=len(instance)\n",
    "    for i=0 to n: \n",
    "        sublists = sublists + [all sublists with i elements]\n",
    "    \n",
    "    acceptable_solutions=[all element of sublists which are acceptable]\n",
    "    \n",
    "    durations = [duration of each element of acceptable_solutions]\n",
    "    max_duration = max(durations)\n",
    "    optimal_solutions = [sublists of instance with total duration == max_durations]\n",
    "    \n",
    "    return optimal_solutions, max_duration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement a program that given in input an instance in the form given above, gives the optimal solution.\n",
    "\n",
    "First of all, we create a function ```is_acceptable(solution, instance)``` that says if a solution is acceptable or not, i.e. there is not two consecutive requests of the instance in the solution.\n",
    "\n",
    "Then, the ```longest_acceptable_duration(instance)``` compute all possible sublists of the instance, test it with the function ```is_acceptable(solution, instance)```, sum every acceptable list (to compute the duration of each acceptable solution) and return the maximum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_acceptable(solution, instance):\n",
    "    res=True \n",
    "    for x,y in zip(solution[:-1],solution[1:]):\n",
    "        i= instance.index(x)\n",
    "        #index1 = np.where(np.array(instance) == x)\n",
    "        #for i in index[0]:\n",
    "        #if the next element is y \n",
    "        if instance[i+1] == y:\n",
    "            res = False\n",
    "    return res\n",
    "\n",
    "def optimal_solution(instance):\n",
    "    sublists=[]\n",
    "    \n",
    "    for i in range(1, len(instance)+1):\n",
    "        sublists+=[list(x) for x in combinations(instance, i)]\n",
    "        \n",
    "    mask = [is_acceptable(solution, instance) for solution in sublists]\n",
    "    acceptable_sol = np.array(sublists)[mask]\n",
    "    \n",
    "    durations = [sum(L) for L in acceptable_sol]\n",
    "    max_duration = max(durations)\n",
    "    \n",
    "    index_optimal_solutions = np.where(np.array(durations)==max_duration)\n",
    "    \n",
    "    return list(np.array(acceptable_sol)[index_optimal_solutions]), max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40, 50, 20]] 110\n"
     ]
    }
   ],
   "source": [
    "instance = [30, 40, 25, 50, 30, 20]\n",
    "optimal_solutions, max_duration = optimal_solution(instance)\n",
    "print(optimal_solutions, max_duration)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adm_hm3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
